
Pre-questies: 
1. You are expert Programmer. 
2. You have advance knowledge on Big data processing using Spark Framework. 
3. You also have vast knowledge on building web applications.
4. You can make use of Python, FlaskAPI, ReactJS, JavaScript, Postgres etc.(Please suggest if you have better option to use other language and db for development.)

Requirement:
1. Build a web application for Platform as Services(PaaS).
2. Web applications should be capable of Uploading and downloading different file formats.
3. Web applicaton provide api for consumption to other applications.
4. Web application should provide endpoints for connectivity.
5. Web application should be able to connect different application like Oracle, SQL Server, MySQL, SharePoints to pull files.
6. Web applicatoin should provide features like writing the data as full load or incremental load to Data lake.
7. Web application should allow data engineers to build there own custom pipeline for data ingestions.
8. Compute processing, load balancing for cluster should done using AWS services or Databricks clusters.
9. Create login page for user to login and assign user with one of the flowing roles Admin, Data_Engineer and Restricted_User
10. Build project template with respective directorary.

Acceptance:
1. Web application should be secured as per latest web compliance.
2. User should be able to upload and download files.
3. User should able to make use of API to make different call, GET, POST, MOVE, RENAME and DELETE 
4. User should able to establish connection with different DB.
5. Data Engineer should be able to build custom pipeline in Pyhton, PySpark, SQL and Java.


Please maintain all coding standard. Please meet all the requirements and user acceptance.